<!DOCTYPE html>
<html lang="en">

<head>
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-FTK67N3EL9"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-FTK67N3EL9');
</script>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Sinho Chewi's Website</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/scrolling-nav.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<!-- The #page-top ID is part of the scrolling feature - the data-spy and data-target are part of the built-in Bootstrap scrollspy function -->

{% block body %}
<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand page-scroll" href="/">Home</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse navbar-ex1-collapse">
                <ul class="nav navbar-nav">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->
                    <li class="hidden">
                        <a class="page-scroll" href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#drp">DRP (IAP 2019)</a>
                    </li>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Intro Section -->
    <section id="drp" class="extra-section">
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <h1>DRP (IAP 2019)</h1>
                    <p>This is the webpage for a directed reading program (DRP) I am leading during MIT's Independent Activities Period (IAP 2019). The subject is high-dimensional statistics.</p>
                    <h3>References</h3>
                    <ul>
                        <li><b>[Ko] Koltchinskii, <i>Oracle Inequalities in Empirical Risk Minimization and Sparse Recovery Problems</i> (2011).</b></li>
                        <li>[BvdG] BÃ¼hlmann and van de Geer, <i>Statistics for High-Dimensional Data</i> (2011).</li>
                        <li>[Ke] Keener, <i>Theoretical Statistics</i> (2010).</li>
                        <li>[vdVW] van der Vaart and Wellner, <i>Weak Convergence and Empirical Processes</i> (1996).</li>
                        <li>[vH] van Handel, <i>Probability in High Dimension</i> (2016).</li>
                        <li>[V] Vershynin, <i>High-Dimensional Probability</i> (2018).</li>
                    </ul>
                    <h3>Readings</h3>
                    <ul>
                        <li>(preparation) The basic language of measure theory, and a preview of the topics in the reading group. [Ke] 1.1-1.6, [Ko] 1.1-1.7.</li>
                        <li>(1/7) Concentration inequalities: Hoeffding, bounded difference, Talagrand, Bosquet. Sub-Gaussian random variables and Orlicz norms. [V] 2.1-2.2, 2.5, 2.7.1, [Ko] 2.3.</li>
                        <li>(1/9) Covering/packing and the volumetric argument. Chaining and Dudley's entropy integral. [V] 4.2, 8.1 (skip 8.1.2), [Ko] 3.1.</li>
                        <li>(1/11) Symmetrization and contraction principle. Rademacher complexity of finite classes of functions. [vH] 7.1, [Ko] 2.1-2.2, 3.2.</li>
                        <li>(1/14) Vapnik-Chervonenkis (VC) dimension: Pajor's lemma, Sauer-Shelah lemma. Uniform Glivenko-Cantelli classes. [V] 8.3, [Ko] 3.3.</li>
                        <li>(1/16) VC subgraph classes. Fat-shattering dimension and the Mendelson-Vershynin bound on covering numbers. [vdVW] 2.6.2, [vH] 7.3.</li>
                        <li>(1/18) Distribution-dependent excess risk bounds via fixed-point argument. Excess risk bounds for regression with quadratic loss. [Ko] 4.1, 5.1.</li>
                        <li>(1/22) Upper bound for random metric entropy. Excess risk bounds for empirical risk minimization with convex loss. [Ko] 3.4, 5.2.</li>
                        <li>(1/23) Data-dependent bounds on excess risk. Model selection via penalized empirical risk minimization for monotone families. [Ko] 4.2, 6.1.</li>
                        <li>(1/25) Statistical guarantees for least absolute shrinkage and selection operator (LASSO) in sparse linear regression with fixed design. LASSO for general convex loss functions. Compatibility condition and the restricted isometry property (RIP). [BvdG] 6.1-6.2.2, 6.3, [V] 10.5.2.</li>
                        <li>(1/28) Statistical guarantees for L2Boosting with componentwise linear least squares base procedure for sparse linear regression. [BvdG] 12.1-12.2, 12.4.4.1, 12.5.1, 12.5.4-12.5.5, 12.6.2.2, 12.8.2.</li>
                        <li>(1/30) Implicit regularization. Gunasekar et al., <a href="https://arxiv.org/abs/1802.08246"><i>Characterizing implicit bias in terms of optimization geometry</i></a> (2018).</li>
                    </ul>
                    <h3>Exercises</h3>
                    <ul>
                        <li><a href="https://drive.google.com/open?id=1TeA9ndc5eloIB5X7Sc7bLL6pmtd0Qo3A">1/7</li>
                        <li><a href="https://drive.google.com/open?id=1wJ392Wk3oPjwqWvqfU-Q8d8jxN7qatwv">1/9</li>
                        <li><a href="https://drive.google.com/open?id=1xtL_CCAUmEnwqkKaeMWXcF2PX3mPTPyY">1/11</li>
                        <li><a href="https://drive.google.com/open?id=1AYRxGJx_9bHyzFkWKlqnsR7gz47j0khP">1/14</li>
                        <li><a href="https://drive.google.com/open?id=1LRwnCFNLc76nJL99u_zPHFnD5WYG4txr">1/16</li>
                        <li><a href="https://drive.google.com/open?id=1l9EJ2ITSpp8Bx_l-jH9MNuhduKQcaExC">1/18</li>
                        <li><a href="https://drive.google.com/open?id=1dI5WHoBGLhaUzLVyAVPlYhkdWFn2XyuI">1/22</li>
                        <li><a href="https://drive.google.com/open?id=14hJYHt3p8ZkJqkIagcp_nKKRNIFWRzCV">1/23</li>
                        <li><a href="https://drive.google.com/open?id=1_lZtaQimK7JedU7AvI7gIS9IhVh40QMj">1/25</li>
                        <li><a href="https://drive.google.com/open?id=12gWWYdKdcIUbjWOKtRPaAU10VIJbMFx-">1/28</li>
                        <li><a href="https://drive.google.com/open?id=1AS_opY_dcaX8jK5qpMN23N40GhXhrJu_">1/30</li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

</body>
{% endblock %}

</html>
